pub_date	title	venue	excerpt	citation	url_slug	paper_url	bibtex	abstract
2017-03-10	Data-Driven Color Augmentation Techniques for Deep Skin Image Analysis	arXiv preprint arXiv:1703.03702	Notes.	A. Galdran, A. Alvarez-Gila, M.I. Meyer, C. L. Saratxaga, T. Araújo, E. Garrote, G. Aresta, P. Costa, A.M. Mendonça, A. Campilho, “Data-Driven Color Augmentation Techniques for Deep Skin Image Analysis,” Mar. 2017.	galdran_data-driven_2017	https://arxiv.org/abs/1703.03702	galdran_data-driven_2017.bib	Dermoscopic skin images are often obtained with different imaging devices, under varying acquisition conditions. In this work, instead of attempting to perform intensity and color normalization, we propose to leverage computational color constancy techniques to build an artificial data augmentation technique suitable for this kind of images. Specifically, we apply the \emph{shades of gray} color constancy technique to color-normalize the entire training set of images, while retaining the estimated illuminants. We then draw one sample from the distribution of training set illuminants and apply it on the normalized image. We employ this technique for training two deep convolutional neural networks for the tasks of skin lesion segmentation and skin lesion classification, in the context of the ISIC 2017 challenge and without using any external dermatologic image set. Our results on the validation set are promising, and will be supplemented with extended results on the hidden test set when available.
2016-09-08	Deep Convolutional Neural Networks for surface quality inspection of hot long metal products	First European Machine Vision Forum	Notes.	A. Alvarez-Gila, A. Lopez-Cruz, S. Rodriguez-Vaamonde, M. Linares, J. A. Gutierrez-Olabarria, and E. Garrote, “Deep Convolutional Neural Networks for surface quality inspection of hot long metal products,” presented at the First European Machine Vision Forum, Heidelberg, Germany, 2016.	alvarez-gila_deep_2016	http://www.computervisionbytecnalia.com/wp-content/uploads/2016/09/EMVA-Deep-Convolutional-Neuronal-Networks-for-surface-quality-inspection-of-hot-long-metal-products.pdf	alvarez-gila_deep_2016.bib	This paper presents the advances incorporated into Tecnalia’s SURFIN surface quality inspection system. SURFIN performs real-time detection and classification of external defects (e.g. roll marks, cracks, etc.) from the manufacturing process of metallic products such as bars, tubes, billets, slabs, beam blanks or structural profiles. The equipment is installed in the production line. It can detect defects at the early stages in the production process, when the product is still incandescent (>1000ºC). This allows preventing the unnecessary addition of value to it. The system is based on laser triangulation and machine learning techniques.\nWe have upgraded SURFIN by replacing the previous commercial software-based detection and classification module –supported by opaque handcrafted feature extraction and Support Vector Machines (SVM)– with an in-house made candidate window detection stage and a Convolutional Neural Network (CNN) performing the actual defect classification (CNNSURFIN). The image database includes 3886 cropped images from long hot bars (2475 good and 1411 showing three defect categories). We evaluated CNN-SURFIN architecturebased classifier over these in a 10-fold cross validation setup for good vs. bad classification, finding that it (AUC=0.9970) significantly outperformed the commercial SVM-based classifier (AUC=0.88). We have also implemented two baselines by extracting texture features (LBP) and training an SVM (AUC=0.92) and a Random Forest classifier (AUC=0.95) on top of these, further supporting the superiority of the deep learning-based approach. Finally, we trained CNN-SURFIN for the full 4-class classification problem, yielding an AUC of 0.9956.
2015-01-31	Automatic Red-Channel underwater image restoration	Journal of Visual Communication and Image Representation	Notes.	A. Galdran, D. Pardo, A. Picón, and A. Alvarez-Gila, “Automatic Red-Channel underwater image restoration,” Journal of Visual Communication and Image Representation, vol. 26, pp. 132–145, Jan. 2015.	galdran_automatic_2015	http://www.academia.edu/download/40429159/Automatic_Red-Channel_underwater_image_r20151127-13023-t6apld.pdf	2015-01-31-galdran_automatic_2015.bib	Underwater images typically exhibit color distortion and low contrast as a result of the exponential decay that light suffers as it travels. Moreover, colors associated to different wavelengths have different attenuation rates, being the red wavelength the one that attenuates the fastest. To restore underwater images, we propose a Red Channel method, where colors associated to short wavelengths are recovered, as expected for underwater images, leading to a recovery of the lost contrast. The Red Channel method can be interpreted as a variant of the Dark Channel method used for images degraded by the atmosphere when exposed to haze. Experimental results show that our technique handles gracefully artificially illuminated areas, and achieves a natural color correction and superior or equivalent visibility improvement when compared to other state-of-the-art methods.
2010-06-14	Combining color descriptors for improved codebook model-based image retrieval	5th European Conference on Colour in Graphics, Imaging, and Vision 2010	Notes	A. Alvarez-Gila, G. Cao, S. F. Hasan, and Y. Hu, “Combining color descriptors for improved codebook model-based image retrieval,” Conference on Colour in Graphics, Imaging, and Vision, vol. 2010, no. 1, pp. 306–313, Jun. 2010.	alvarez-gila_combining_2010	http://colorlab.no/content/download/28379/325582/file/Gila2010.pdf	2010-06-14-alvarez-gila_combining_2010.bib	In this paper we present the design of an image Content-Based Indexing and Retrieval (CBIR) system which, based upon existing implementations of a number of well-known color descriptors, makes use of the bag-of-words or codebook model in order to construct a robust approach to the retrieval of images from a database in a query-by-example context. A new object image database was constructed specifically for this task, in an attempt to challenge the invariance properties of the system under controlled conditions of illumination, point of view and scale. The system permits the combined use of up to two of the different color descriptors considered. The experiments run over a subset of the image database show an improvement of the obtained results under some of the tested combinations, as well as the effect of the variation of the employed codebook size.
